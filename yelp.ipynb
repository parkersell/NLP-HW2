{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "INPUT_FOLDER = \"/mnt/d/Spring 2023 Big Files/\"\n",
    "OUTPUT_FOLDER = \"/mnt/d/Spring 2023 Big Files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yelp_orig_data(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    PATH_TO_YELP_REVIEWS = os.path.join(INPUT_FOLDER,\"output.json\")\n",
    "\n",
    "    # read the entire file into a python array\n",
    "    with open(PATH_TO_YELP_REVIEWS, 'r') as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    # remove the trailing \"\\n\" from each line\n",
    "    data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "    data_json_str = \"[\" , ','.join(data) , \"]\"\n",
    "\n",
    "    # now, load it into pandas\n",
    "    data_df = pd.read_json(data_json_str)\n",
    "\n",
    "    data_df.head(100000).to_csv(path)\n",
    "\n",
    "load_yelp_orig_data(path = os.path.join(OUTPUT_FOLDER, 'output_reviews_top.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the original dataset:\n",
      "\n",
      "Index(['Unnamed: 0', 'review_id', 'user_id', 'business_id', 'stars', 'useful',\n",
      "       'funny', 'cool', 'text', 'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "top_data_df = pd.read_csv(os.path.join(INPUT_FOLDER , 'output_reviews_top.csv'))\n",
    "print(\"Columns in the original dataset:\\n\")\n",
    "print(top_data_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows per star rating:\n",
      "5    44392\n",
      "4    25337\n",
      "3    11362\n",
      "1    10921\n",
      "2     7988\n",
      "Name: stars, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHGCAYAAABpZb/eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHc0lEQVR4nO3de1iUdf7/8RegHDzM4BEkUUwtxWOiIpapRZKxWyamlhWa2mpoKnncCg+7ra4dzPKU9U0sc1Pb8lceMEPRSlKjzEPpZmG6KeAJRilB4f790Zf76wjpPQbOqM/Hdc11OffnPZ/7PePUvLznc9/jZRiGIQAAAFyUt7sbAAAAuBoQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJqA69jAgQMVFhbm7jauiOTkZHl5eenAgQPmtm7duqlbt25XZP9eXl6aMmWKeX/KlCny8vLSsWPHrsj+w8LCNHDgwCuyr/OV9bpXhAMHDsjLy0vJyclO21NSUtS2bVv5+/vLy8tLubm5FdoHrm2EJuAK2bVrl/r06aOGDRvK399fN9xwg+666y69+uqrFbrfw4cPa8qUKdqxY0eF7qei/PLLL5oyZYrS0tLc3YokacuWLZoyZYpHfvh6cm/ucPz4cfXt21cBAQGaO3eu3n77bVWtWtXdbeEqVsndDQDXgy1btqh79+5q0KCBhg4dquDgYB06dEhffPGFZs+erZEjR1bYvg8fPqypU6cqLCxMbdu2dRp7/fXXVVxcXGH7Lg+//PKLpk6dKknlflTo448/dvkxW7Zs0dSpUzVw4EAFBgZaftyvv/6qSpUq9n+5F+tt37598va+8v9OfuSRR9S/f3/5+fld8X1v375dp06d0t/+9jdFR0df8f3j2kNoAq6A5557Tna7Xdu3by/1YZaTk+OepiRVrlzZbfv2BL6+vhU6f3FxsQoLC+Xv7y9/f/8K3deluCO0SJKPj498fHzcsu+S/7ZcCbfAxfD1HHAF/PDDD2rRokWZ//OuW7duqW1LlixRRESEAgICVLNmTfXv31+HDh1yqunWrZtatmypb7/9Vt27d1eVKlV0ww03aObMmWZNWlqaOnToIEkaNGiQvLy8nNZ9XLimqWRdyAsvvKC5c+fqxhtvVJUqVdSjRw8dOnRIhmHob3/7m+rXr6+AgADdd999OnHiRKn+165dqy5duqhq1aqqXr26YmNjtWfPHqeagQMHqlq1avr555/Vq1cvVatWTXXq1NHYsWNVVFRk9lOnTh1J0tSpU83+z18bVJY9e/bojjvuUEBAgOrXr6+///3vZR5RK2tN06uvvqoWLVqoSpUqqlGjhtq3b6+lS5dK+m0d0rhx4yRJjRo1MvspWa/j5eWlESNG6J133lGLFi3k5+enlJQUc6ysvo8dO6a+ffvKZrOpVq1aGjVqlM6cOVPq7+TCtToXznmp3spa0/Tjjz/qgQceUM2aNVWlShV16tRJq1evdqpJS0uTl5eXli9frueee07169eXv7+/7rzzTu3fv79UTxcqa01TWFiY/vSnP+mzzz5Tx44d5e/vrxtvvFFvvfXWJeeTpNzcXA0cOFB2u12BgYGKj48v9ZVkt27dFB8fL0nq0KGDvLy83LKmC9cWjjQBV0DDhg2Vnp6u3bt3q2XLlhetfe655/Tss8+qb9++GjJkiI4ePapXX31Vt99+u77++mun4HXy5Endfffd6t27t/r27av33ntPEyZMUKtWrdSzZ081b95c06ZNU1JSkh5//HF16dJFktS5c+eL9vDOO++osLBQI0eO1IkTJzRz5kz17dtXd9xxh9LS0jRhwgTt379fr776qsaOHas333zTfOzbb7+t+Ph4xcTE6J///Kd++eUXzZ8/X7fddpu+/vprp5BWVFSkmJgYRUZG6oUXXtAnn3yiF198UY0bN9bw4cNVp04dzZ8/X8OHD9f999+v3r17S5Jat279u71nZWWpe/fuOnfunCZOnKiqVatq4cKFCggIuOhzln77uvLJJ59Unz59zPCyc+dObd26VQ899JB69+6t//znP/rXv/6lWbNmqXbt2pJkBjtJ2rBhg5YvX64RI0aodu3al1xo37dvX4WFhWn69On64osv9Morr+jkyZOWA0QJK72dLzs7W507d9Yvv/yiJ598UrVq1dLixYt177336r333tP999/vVD9jxgx5e3tr7NixysvL08yZMzVgwABt3brVpT5L7N+/X3369NHgwYMVHx+vN998UwMHDlRERIRatGjxu48zDEP33XefPvvsMw0bNkzNmzfXBx98YAakEk8//bRuvvlmLVy4UNOmTVOjRo3UuHHjy+oVMBkAKtzHH39s+Pj4GD4+PkZUVJQxfvx4Y926dUZhYaFT3YEDBwwfHx/jueeec9q+a9cuo1KlSk7bu3btakgy3nrrLXNbQUGBERwcbMTFxZnbtm/fbkgyFi1aVKqv+Ph4o2HDhub9zMxMQ5JRp04dIzc319w+adIkQ5LRpk0b4+zZs+b2Bx980PD19TXOnDljGIZhnDp1yggMDDSGDh3qtJ+srCzDbrc7bY+PjzckGdOmTXOqveWWW4yIiAjz/tGjRw1JxuTJk0v1X5bRo0cbkoytW7ea23Jycgy73W5IMjIzM83tXbt2Nbp27Wrev++++4wWLVpcdP7nn3++1DwlJBne3t7Gnj17yhw7/zlMnjzZkGTce++9TnVPPPGEIcn45ptvDMP4v7+Tsv7+LpzzYr01bNjQiI+PN++XvE6ffvqpue3UqVNGo0aNjLCwMKOoqMgwDMPYuHGjIclo3ry5UVBQYNbOnj3bkGTs2rWr1L7Ot2jRolI9NWzY0JBkbN682dyWk5Nj+Pn5GU899dRF51u5cqUhyZg5c6a57dy5c0aXLl1KvU4l+96+fftF5wSs4us54Aq46667lJ6ernvvvVfffPONZs6cqZiYGN1www368MMPzbr3339fxcXF6tu3r44dO2begoOD1bRpU23cuNFp3mrVqunhhx827/v6+qpjx4768ccf/1C/DzzwgOx2u3k/MjJSkvTwww87LWaOjIxUYWGhfv75Z0nS+vXrlZubqwcffNCpfx8fH0VGRpbqX5KGDRvmdL9Lly5/qP81a9aoU6dO6tixo7mtTp06GjBgwCUfGxgYqP/+97/avn37Ze+/a9euCg8Pt1yfkJDgdL/kpIA1a9Zcdg9WrFmzRh07dtRtt91mbqtWrZoef/xxHThwQN9++61T/aBBg5zWgJUctbzcv6vw8HBzDum3v6Obb775kvOtWbNGlSpV0vDhw81tPj4+FXoyBVCC0ARcIR06dND777+vkydPatu2bZo0aZJOnTqlPn36mB9Q33//vQzDUNOmTVWnTh2n23fffVdq0Xj9+vXl5eXltK1GjRo6efLkH+q1QYMGTvdLAlRoaGiZ20v29/3330uS7rjjjlL9f/zxx6X69/f3L/X10R/t/6efflLTpk1Lbb/55psv+dgJEyaoWrVq6tixo5o2baqEhAR9/vnnLu2/UaNGLtVf2Gvjxo3l7e1d4dc1+umnn8p8TZo3b26On+/C90SNGjUk6bL/ri6cr2TOS833008/qV69eqpWrZrTdit/v8AfxZom4Arz9fVVhw4d1KFDB910000aNGiQVqxYocmTJ6u4uFheXl5au3ZtmWccXfhB8XtnJRmG8Yd6/L15L7W/ksXWb7/9toKDg0vVXXjKvbvOqvo9zZs31759+7Rq1SqlpKTo3//+t+bNm6ekpCTzsgeXYmXt1MVcGIIvvF+iZLH8lVLe77WKeu8CFYnQBLhR+/btJUlHjhyR9NtRBsMw1KhRI910003lso/f+9CtCCULbevWrVtu18Vxtf+GDRuaR7zOt2/fPkuPr1q1qvr166d+/fqpsLBQvXv31nPPPadJkyaZV5UuT99//73T0an9+/eruLjYXEBeckTnwrPDLjwSJLn2WjVs2LDM12Tv3r3muCdq2LChUlNTdfr0aad/RFj9+wX+CL6eA66AjRs3lvkv6JJ1KyVfLfTu3Vs+Pj6aOnVqqXrDMHT8+HGX911yBeQrcZXomJgY2Ww2/eMf/9DZs2dLjR89etTlOatUqSLJev/33HOPvvjiC23bts1pv++8884lH3vh6+vr66vw8HAZhmE+n/J+PefOnet0v+QK8T179pQk2Ww21a5dW5s3b3aqmzdvXqm5XOntnnvu0bZt25Senm5uy8/P18KFCxUWFubSuqwr6Z577tG5c+c0f/58c1tRUVGFX1kfkDjSBFwRI0eO1C+//KL7779fzZo1U2FhobZs2aJly5YpLCxMgwYNkvTbkZq///3vmjRpkg4cOKBevXqpevXqyszM1AcffKDHH39cY8eOdWnfjRs3VmBgoBYsWKDq1auratWqioyMdHntjRU2m03z58/XI488onbt2ql///6qU6eODh48qNWrV+vWW2/VnDlzXJozICBA4eHhWrZsmW666SbVrFlTLVu2/N1LN4wfP15vv/227r77bo0aNcq85EDDhg21c+fOi+6rR48eCg4O1q233qqgoCB99913mjNnjmJjY1W9enVJUkREhKTfTmnv37+/KleurD//+c+X/fMcmZmZuvfee3X33XcrPT1dS5Ys0UMPPaQ2bdqYNUOGDNGMGTM0ZMgQtW/fXps3b9Z//vOfUnO50tvEiRP1r3/9Sz179tSTTz6pmjVravHixcrMzNS///1vt1w93Io///nPuvXWWzVx4kQdOHBA4eHhev/995WXl+fu1nAdIDQBV8ALL7ygFStWaM2aNVq4cKEKCwvVoEEDPfHEE3rmmWecrr00ceJE3XTTTZo1a5a5jiY0NFQ9evTQvffe6/K+K1eurMWLF2vSpEkaNmyYzp07p0WLFlVIaJKkhx56SCEhIZoxY4aef/55FRQU6IYbblCXLl3McOiqN954QyNHjtSYMWNUWFioyZMn/25oqlevnjZu3KiRI0dqxowZqlWrloYNG6aQkBANHjz4ovv5y1/+onfeeUcvvfSSTp8+rfr16+vJJ5/UM888Y9Z06NBBf/vb37RgwQKlpKSouLhYmZmZlx2ali1bpqSkJE2cOFGVKlXSiBEj9PzzzzvVJCUl6ejRo3rvvfe0fPly9ezZU2vXri11YVRXegsKCtKWLVs0YcIEvfrqqzpz5oxat26tjz76SLGxsZf1XK4Eb29vffjhhxo9erSWLFkiLy8v3XvvvXrxxRd1yy23uLs9XOO8DFbdAQAAXJJnHn8FAADwMIQmAAAACwhNAAAAFhCaAAAALCA0AQAAWMAlB8pJcXGxDh8+rOrVq1/RKzADAIDLZxiGTp06pZCQkEten4zQVE4OHz5c6sdMAQDA1eHQoUOqX7/+RWsITeWk5GrBhw4dks1mc3M3AADACofDodDQUPNz/GIITeWk5Cs5m81GaAIA4CpjZWkNC8EBAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWODW0BQWFiYvL69St4SEBEnSmTNnlJCQoFq1aqlatWqKi4tTdna20xwHDx5UbGysqlSporp162rcuHE6d+6cU01aWpratWsnPz8/NWnSRMnJyaV6mTt3rsLCwuTv76/IyEht27atwp43AAC4+rg1NG3fvl1Hjhwxb+vXr5ckPfDAA5KkMWPG6KOPPtKKFSu0adMmHT58WL179zYfX1RUpNjYWBUWFmrLli1avHixkpOTlZSUZNZkZmYqNjZW3bt3144dOzR69GgNGTJE69atM2uWLVumxMRETZ48WV999ZXatGmjmJgY5eTkXKFXAgAAeDzDg4waNcpo3LixUVxcbOTm5hqVK1c2VqxYYY5/9913hiQjPT3dMAzDWLNmjeHt7W1kZWWZNfPnzzdsNptRUFBgGIZhjB8/3mjRooXTfvr162fExMSY9zt27GgkJCSY94uKioyQkBBj+vTplnvPy8szJBl5eXmuPWkAAOA2rnx+e8yapsLCQi1ZskSPPfaYvLy8lJGRobNnzyo6OtqsadasmRo0aKD09HRJUnp6ulq1aqWgoCCzJiYmRg6HQ3v27DFrzp+jpKZkjsLCQmVkZDjVeHt7Kzo62qwpS0FBgRwOh9MNAABcuzwmNK1cuVK5ubkaOHCgJCkrK0u+vr4KDAx0qgsKClJWVpZZc35gKhkvGbtYjcPh0K+//qpjx46pqKiozJqSOcoyffp02e128xYaGurycwYAAFePSu5uoMT//M//qGfPngoJCXF3K5ZMmjRJiYmJ5n2Hw3FVBKewiavd3cI148CMWHe3AAC4gjwiNP3000/65JNP9P7775vbgoODVVhYqNzcXKejTdnZ2QoODjZrLjzLreTsuvNrLjzjLjs7WzabTQEBAfLx8ZGPj0+ZNSVzlMXPz09+fn6uP1kAAHBV8oiv5xYtWqS6desqNvb//uUeERGhypUrKzU11dy2b98+HTx4UFFRUZKkqKgo7dq1y+kst/Xr18tmsyk8PNysOX+OkpqSOXx9fRUREeFUU1xcrNTUVLMGAADA7UeaiouLtWjRIsXHx6tSpf9rx263a/DgwUpMTFTNmjVls9k0cuRIRUVFqVOnTpKkHj16KDw8XI888ohmzpyprKwsPfPMM0pISDCPAg0bNkxz5szR+PHj9dhjj2nDhg1avny5Vq/+v6+pEhMTFR8fr/bt26tjx456+eWXlZ+fr0GDBl3ZFwMAAHgst4emTz75RAcPHtRjjz1WamzWrFny9vZWXFycCgoKFBMTo3nz5pnjPj4+WrVqlYYPH66oqChVrVpV8fHxmjZtmlnTqFEjrV69WmPGjNHs2bNVv359vfHGG4qJiTFr+vXrp6NHjyopKUlZWVlq27atUlJSSi0OBwAA1y8vwzAMdzdxLXA4HLLb7crLy5PNZnN3O7+LheDlh4XgAHD1c+Xz2yPWNAEAAHg6QhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYIHbQ9PPP/+shx9+WLVq1VJAQIBatWqlL7/80hw3DENJSUmqV6+eAgICFB0dre+//95pjhMnTmjAgAGy2WwKDAzU4MGDdfr0aaeanTt3qkuXLvL391doaKhmzpxZqpcVK1aoWbNm8vf3V6tWrbRmzZqKedIAAOCq49bQdPLkSd16662qXLmy1q5dq2+//VYvvviiatSoYdbMnDlTr7zyihYsWKCtW7eqatWqiomJ0ZkzZ8yaAQMGaM+ePVq/fr1WrVqlzZs36/HHHzfHHQ6HevTooYYNGyojI0PPP/+8pkyZooULF5o1W7Zs0YMPPqjBgwfr66+/Vq9evdSrVy/t3r37yrwYAADAo3kZhmG4a+cTJ07U559/rk8//bTMccMwFBISoqeeekpjx46VJOXl5SkoKEjJycnq37+/vvvuO4WHh2v79u1q3769JCklJUX33HOP/vvf/yokJETz58/X008/raysLPn6+pr7Xrlypfbu3StJ6tevn/Lz87Vq1Spz/506dVLbtm21YMGCUr0VFBSooKDAvO9wOBQaGqq8vDzZbLbyeYEqQNjE1e5u4ZpxYEasu1sAAPxBDodDdrvd0ue3W480ffjhh2rfvr0eeOAB1a1bV7fccotef/11czwzM1NZWVmKjo42t9ntdkVGRio9PV2SlJ6ersDAQDMwSVJ0dLS8vb21detWs+b22283A5MkxcTEaN++fTp58qRZc/5+SmpK9nOh6dOny263m7fQ0NA/+GoAAABP5tbQ9OOPP2r+/Plq2rSp1q1bp+HDh+vJJ5/U4sWLJUlZWVmSpKCgIKfHBQUFmWNZWVmqW7eu03ilSpVUs2ZNp5qy5jh/H79XUzJ+oUmTJikvL8+8HTp0yOXnDwAArh6V3Lnz4uJitW/fXv/4xz8kSbfccot2796tBQsWKD4+3p2tXZKfn5/8/Pzc3QYAALhC3HqkqV69egoPD3fa1rx5cx08eFCSFBwcLEnKzs52qsnOzjbHgoODlZOT4zR+7tw5nThxwqmmrDnO38fv1ZSMAwCA65tbQ9Ott96qffv2OW37z3/+o4YNG0qSGjVqpODgYKWmpprjDodDW7duVVRUlCQpKipKubm5ysjIMGs2bNig4uJiRUZGmjWbN2/W2bNnzZr169fr5ptvNs/Ui4qKctpPSU3JfgAAwPXNraFpzJgx+uKLL/SPf/xD+/fv19KlS7Vw4UIlJCRIkry8vDR69Gj9/e9/14cffqhdu3bp0UcfVUhIiHr16iXptyNTd999t4YOHapt27bp888/14gRI9S/f3+FhIRIkh566CH5+vpq8ODB2rNnj5YtW6bZs2crMTHR7GXUqFFKSUnRiy++qL1792rKlCn68ssvNWLEiCv+ugAAAM/j1jVNHTp00AcffKBJkyZp2rRpatSokV5++WUNGDDArBk/frzy8/P1+OOPKzc3V7fddptSUlLk7+9v1rzzzjsaMWKE7rzzTnl7eysuLk6vvPKKOW632/Xxxx8rISFBERERql27tpKSkpyu5dS5c2ctXbpUzzzzjP7617+qadOmWrlypVq2bHllXgwAAODR3HqdpmuJK9d5cCeu01R+uE4TAFz9rprrNAEAAFwtCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAK3hqYpU6bIy8vL6dasWTNz/MyZM0pISFCtWrVUrVo1xcXFKTs722mOgwcPKjY2VlWqVFHdunU1btw4nTt3zqkmLS1N7dq1k5+fn5o0aaLk5ORSvcydO1dhYWHy9/dXZGSktm3bViHPGQAAXJ3cfqSpRYsWOnLkiHn77LPPzLExY8boo48+0ooVK7Rp0yYdPnxYvXv3NseLiooUGxurwsJCbdmyRYsXL1ZycrKSkpLMmszMTMXGxqp79+7asWOHRo8erSFDhmjdunVmzbJly5SYmKjJkyfrq6++Ups2bRQTE6OcnJwr8yIAAACP52UYhuGunU+ZMkUrV67Ujh07So3l5eWpTp06Wrp0qfr06SNJ2rt3r5o3b6709HR16tRJa9eu1Z/+9CcdPnxYQUFBkqQFCxZowoQJOnr0qHx9fTVhwgStXr1au3fvNufu37+/cnNzlZKSIkmKjIxUhw4dNGfOHElScXGxQkNDNXLkSE2cONHSc3E4HLLb7crLy5PNZvsjL0uFCpu42t0tXDMOzIh1dwsAgD/Ilc9vtx9p+v777xUSEqIbb7xRAwYM0MGDByVJGRkZOnv2rKKjo83aZs2aqUGDBkpPT5ckpaenq1WrVmZgkqSYmBg5HA7t2bPHrDl/jpKakjkKCwuVkZHhVOPt7a3o6GizpiwFBQVyOBxONwAAcO1ya2iKjIxUcnKyUlJSNH/+fGVmZqpLly46deqUsrKy5Ovrq8DAQKfHBAUFKSsrS5KUlZXlFJhKxkvGLlbjcDj066+/6tixYyoqKiqzpmSOskyfPl12u928hYaGXtZrAAAArg6V3Lnznj17mn9u3bq1IiMj1bBhQy1fvlwBAQFu7OzSJk2apMTERPO+w+EgOAEAcA1z+9dz5wsMDNRNN92k/fv3Kzg4WIWFhcrNzXWqyc7OVnBwsCQpODi41Nl0JfcvVWOz2RQQEKDatWvLx8enzJqSOcri5+cnm83mdAMAANcujwpNp0+f1g8//KB69eopIiJClStXVmpqqjm+b98+HTx4UFFRUZKkqKgo7dq1y+kst/Xr18tmsyk8PNysOX+OkpqSOXx9fRUREeFUU1xcrNTUVLMGAADAraFp7Nix2rRpkw4cOKAtW7bo/vvvl4+Pjx588EHZ7XYNHjxYiYmJ2rhxozIyMjRo0CBFRUWpU6dOkqQePXooPDxcjzzyiL755hutW7dOzzzzjBISEuTn5ydJGjZsmH788UeNHz9ee/fu1bx587R8+XKNGTPG7CMxMVGvv/66Fi9erO+++07Dhw9Xfn6+Bg0a5JbXBQAAeB63rmn673//qwcffFDHjx9XnTp1dNttt+mLL75QnTp1JEmzZs2St7e34uLiVFBQoJiYGM2bN898vI+Pj1atWqXhw4crKipKVatWVXx8vKZNm2bWNGrUSKtXr9aYMWM0e/Zs1a9fX2+88YZiYmLMmn79+uno0aNKSkpSVlaW2rZtq5SUlFKLwwEAwPXLrddpupZwnabrD9dpAoCr31V1nSYAAICrAaEJAADAAkITAACABYQmAAAACwhNAAAAFlgKTTt37lRxcXFF9wIAAOCxLIWmW265RceOHZMk3XjjjTp+/HiFNgUAAOBpLIWmwMBAZWZmSpIOHDjAUScAAHDdsXRF8Li4OHXt2lX16tWTl5eX2rdvLx8fnzJrf/zxx3JtEAAAwBNYCk0LFy5U7969tX//fj355JMaOnSoqlevXtG9AQAAeAzLvz139913S5IyMjI0atQoQhMAALiuuPyDvYsWLaqIPgAAADyapdDUu3dvyxO+//77l90MAACAp7J09pzdbjdvNptNqamp+vLLL83xjIwMpaamym63V1ijAAAA7mTpSNP5X8lNmDBBffv21YIFC8wz6IqKivTEE0/IZrNVTJcAAABu5vLPqLz55psaO3as0yUHfHx8lJiYqDfffLNcmwMAAPAULoemc+fOae/evaW27927l4teAgCAa5bLZ88NGjRIgwcP1g8//KCOHTtKkrZu3aoZM2Zo0KBB5d4gAACAJ3A5NL3wwgsKDg7Wiy++qCNHjkiS6tWrp3Hjxumpp54q9wYBAAA8gcuhydvbW+PHj9f48ePlcDgkiQXgAADgmudyaDofYQkAAFwvXF4IDgAAcD0iNAEAAFhAaAIAALCA0AQAAGDBZS0ET01NVWpqqnJyckpd0JKrggMAgGuRy6Fp6tSpmjZtmtq3b6969erJy8urIvoCAADwKC6HpgULFig5OVmPPPJIRfQDAADgkVxe01RYWKjOnTtXRC8AAAAey+XQNGTIEC1durQiegEAAPBYLn89d+bMGS1cuFCffPKJWrdurcqVKzuNv/TSS+XWHAAAgKdwOTTt3LlTbdu2lSTt3r3baYxF4QAA4FrlcmjauHFjRfQBAADg0bi4JQAAgAWWjjT17t1bycnJstls6t2790Vr33///XJpDAAAwJNYCk12u91cr2S32yu0IQAAAE9kKTQtWrSozD8DAABcL1jTBAAAYAGhCQAAwAJCEwAAgAUeE5pmzJghLy8vjR492tx25swZJSQkqFatWqpWrZri4uKUnZ3t9LiDBw8qNjZWVapUUd26dTVu3DidO3fOqSYtLU3t2rWTn5+fmjRpouTk5FL7nzt3rsLCwuTv76/IyEht27atIp4mAAC4SpVLaMrNzf1Dj9++fbtee+01tW7d2mn7mDFj9NFHH2nFihXatGmTDh8+7HTJg6KiIsXGxqqwsFBbtmzR4sWLlZycrKSkJLMmMzNTsbGx6t69u3bs2KHRo0dryJAhWrdunVmzbNkyJSYmavLkyfrqq6/Upk0bxcTEKCcn5w89LwAAcO1wOTT985//1LJly8z7ffv2Va1atXTDDTfom2++cbmB06dPa8CAAXr99ddVo0YNc3teXp7+53/+Ry+99JLuuOMORUREaNGiRdqyZYu++OILSdLHH3+sb7/9VkuWLFHbtm3Vs2dP/e1vf9PcuXNVWFgoSVqwYIEaNWqkF198Uc2bN9eIESPUp08fzZo1y9zXSy+9pKFDh2rQoEEKDw/XggULVKVKFb355pu/23dBQYEcDofTDQAAXLtcDk0LFixQaGioJGn9+vVav3691q5dq549e2rcuHEuN5CQkKDY2FhFR0c7bc/IyNDZs2edtjdr1kwNGjRQenq6JCk9PV2tWrVSUFCQWRMTEyOHw6E9e/aYNRfOHRMTY85RWFiojIwMpxpvb29FR0ebNWWZPn267Ha7eSt5TQAAwLXJ5d+ey8rKMgPCqlWr1LdvX/Xo0UNhYWGKjIx0aa53331XX331lbZv317mfnx9fRUYGOi0PSgoSFlZWWbN+YGpZLxk7GI1DodDv/76q06ePKmioqIya/bu3fu7vU+aNEmJiYnmfYfDQXACAOAa5vKRpho1aujQoUOSpJSUFPMIjWEYKioqsjzPoUOHNGrUKL3zzjvy9/d3tQ238/Pzk81mc7oBAIBrl8uhqXfv3nrooYd011136fjx4+rZs6ck6euvv1aTJk0sz5ORkaGcnBy1a9dOlSpVUqVKlbRp0ya98sorqlSpkoKCglRYWFhqkXl2draCg4MlScHBwaXOpiu5f6kam82mgIAA1a5dWz4+PmXWlMwBAADgcmiaNWuWRowYofDwcK1fv17VqlWTJB05ckRPPPGE5XnuvPNO7dq1Szt27DBv7du314ABA8w/V65cWampqeZj9u3bp4MHDyoqKkqSFBUVpV27djmd5bZ+/XrZbDaFh4ebNefPUVJTMoevr68iIiKcaoqLi5WammrWAAAAuLymqXLlyho7dmyp7WPGjHFpnurVq6tly5ZO26pWrapatWqZ2wcPHqzExETVrFlTNptNI0eOVFRUlDp16iRJ6tGjh8LDw/XII49o5syZysrK0jPPPKOEhAT5+flJkoYNG6Y5c+Zo/Pjxeuyxx7RhwwYtX75cq1evNvebmJio+Ph4tW/fXh07dtTLL7+s/Px8DRo0yKXnBAAArl0uh6YGDRqoW7du6tq1q7p166bGjRtXRF+Sfjuq5e3trbi4OBUUFCgmJkbz5s0zx318fLRq1SoNHz5cUVFRqlq1quLj4zVt2jSzplGjRlq9erXGjBmj2bNnq379+nrjjTcUExNj1vTr109Hjx5VUlKSsrKy1LZtW6WkpJRaHA4AAK5fXoZhGK48YMmSJdq8ebPS0tK0f/9+3XDDDeratasZopo2bVpRvXo0h8Mhu92uvLw8j14UHjZx9aWLYMmBGbHubgEA8Ae58vnt8pGmhx9+WA8//LCk39Yxbdq0SatWrdITTzyh4uJil86gAwAAuFq4HJok6ZdfftFnn32mtLQ0bdy4UV9//bVatmypbt26lXN7AAAAnsHl0NS5c2d9/fXXat68ubp166aJEyfq9ttvd/oJFAAAgGuNy5cc2Lt3r6pWrapmzZqpWbNmat68OYEJAABc81wOTcePH9eGDRvUqVMnrVu3TrfeeqtuuOEGPfTQQ3r99dcrokcAAAC3c/nsufMZhqGMjAzNmTNH77zzznW9EJyz564/nD0HAFe/Cj177quvvlJaWprS0tL02Wef6dSpU2rVqpVGjhyprl27XnbTAAAAnszl0NSxY0fdcsst6tq1q4YOHarbb79ddru9InoDAADwGC6HphMnTnj0108AAAAVweXQVBKYMjIy9N1330mSwsPD1a5du/LtDAAAwIO4HJpycnLUr18/bdq0SYGBgZKk3Nxcde/eXe+++67q1KlT3j0CAAC4ncuXHBg5cqROnz6tPXv26MSJEzpx4oR2794th8OhJ598siJ6BAAAcDuXjzSlpKTok08+UfPmzc1t4eHhmjt3rnr06FGuzQEAAHgKl480FRcXq3LlyqW2V65cWcXFxeXSFAAAgKdxOTTdcccdGjVqlA4fPmxu+/nnnzVmzBjdeeed5docAACAp3A5NM2ZM0cOh0NhYWFq3LixGjdurEaNGsnhcOjVV1+tiB4BAADczuU1TaGhofrqq6/0ySefaO/evZKk5s2bKzo6utybAwAA8BQuhaazZ88qICBAO3bs0F133aW77rqrovoCAADwKC59PVe5cmU1aNDguv1RXgAAcP1yeU3T008/rb/+9a86ceJERfQDAADgkVxe0zRnzhzt379fISEhatiwoapWreo0/tVXX5VbcwAAAJ7C5dDUq1evCmgDAADAs7kcmiZPnlwRfQAAAHg0l9c0AQAAXI8ITQAAABYQmgAAACywFJocDkdF9wEAAODRLIWmGjVqKCcnR9JvP9ibm5tbkT0BAAB4HEuhqVq1ajp+/LgkKS0tTWfPnq3QpgAAADyNpUsOREdHq3v37mrevLkk6f7775evr2+ZtRs2bCi/7gAAADyEpdC0ZMkSLV68WD/88IM2bdqkFi1aqEqVKhXdGwAAgMewFJoCAgI0bNgwSdKXX36pf/7znwoMDKzIvgAAADyKy1cE37hxo/lnwzAkSV5eXuXXEQAAgAe6rOs0vfXWW2rVqpUCAgIUEBCg1q1b6+233y7v3gAAADyGy0eaXnrpJT377LMaMWKEbr31VknSZ599pmHDhunYsWMaM2ZMuTcJAADgbi6HpldffVXz58/Xo48+am6799571aJFC02ZMoXQBAAArkkufz135MgRde7cudT2zp0768iRI+XSFAAAgKdxOTQ1adJEy5cvL7V92bJlatq0abk0BQAA4Glc/npu6tSp6tevnzZv3myuafr888+VmppaZpgCAAC4Frh8pCkuLk5bt25V7dq1tXLlSq1cuVK1a9fWtm3bdP/997s01/z589W6dWvZbDbZbDZFRUVp7dq15viZM2eUkJCgWrVqqVq1aoqLi1N2drbTHAcPHlRsbKyqVKmiunXraty4cTp37pxTTVpamtq1ayc/Pz81adJEycnJpXqZO3euwsLC5O/vr8jISG3bts2l5wIAAK5tLh9pkqSIiAgtWbLkD++8fv36mjFjhpo2bSrDMLR48WLdd999+vrrr9WiRQuNGTNGq1ev1ooVK2S32zVixAj17t1bn3/+uSSpqKhIsbGxCg4O1pYtW3TkyBE9+uijqly5sv7xj39IkjIzMxUbG6thw4bpnXfeUWpqqoYMGaJ69eopJiZG0m9fLSYmJmrBggWKjIzUyy+/rJiYGO3bt09169b9w88TAABc/byMkitUeoiaNWvq+eefV58+fVSnTh0tXbpUffr0kSTt3btXzZs3V3p6ujp16qS1a9fqT3/6kw4fPqygoCBJ0oIFCzRhwgQdPXpUvr6+mjBhglavXq3du3eb++jfv79yc3OVkpIiSYqMjFSHDh00Z84cSVJxcbFCQ0M1cuRITZw40VLfDodDdrtdeXl5stls5fmSlKuwiavd3cI148CMWHe3AAD4g1z5/L6si1tWhKKiIr377rvKz89XVFSUMjIydPbsWUVHR5s1zZo1U4MGDZSeni5JSk9PV6tWrczAJEkxMTFyOBzas2ePWXP+HCU1JXMUFhYqIyPDqcbb21vR0dFmTVkKCgrkcDicbgAA4Nrl9tC0a9cuVatWTX5+fho2bJg++OADhYeHKysrS76+vqV+4y4oKEhZWVmSpKysLKfAVDJeMnaxGofDoV9//VXHjh1TUVFRmTUlc5Rl+vTpstvt5i00NPSynj8AALg6uD003XzzzdqxY4e2bt2q4cOHKz4+Xt9++62727qkSZMmKS8vz7wdOnTI3S0BAIAKdFkLwcuTr6+vmjRpIum3Bebbt2/X7Nmz1a9fPxUWFio3N9fpaFN2draCg4MlScHBwaXOcis5u+78mgvPuMvOzpbNZlNAQIB8fHzk4+NTZk3JHGXx8/OTn5/f5T1pAABw1Sm3I03z5s3TtGnT/vA8xcXFKigoUEREhCpXrqzU1FRzbN++fTp48KCioqIkSVFRUdq1a5dycnLMmvXr18tmsyk8PNysOX+OkpqSOXx9fRUREeFUU1xcrNTUVLMGAACg3I40/fvf/1ZmZqaSkpIsP2bSpEnq2bOnGjRooFOnTmnp0qVKS0vTunXrZLfbNXjwYCUmJqpmzZqy2WwaOXKkoqKi1KlTJ0lSjx49FB4erkceeUQzZ85UVlaWnnnmGSUkJJhHgYYNG6Y5c+Zo/Pjxeuyxx7RhwwYtX75cq1f/31lkiYmJio+PV/v27dWxY0e9/PLLys/P16BBg8rr5QEAAFe5cgtNFx7NsSInJ0ePPvqojhw5IrvdrtatW2vdunW66667JEmzZs2St7e34uLiVFBQoJiYGM2bN898vI+Pj1atWqXhw4crKipKVatWVXx8vNMRr0aNGmn16tUaM2aMZs+erfr16+uNN94wr9EkSf369dPRo0eVlJSkrKwstW3bVikpKaUWhwMAgOvXH7pOU8lDvby8yq2hqxXXabr+cJ0mALj6Vfh1mt566y21atVKAQEBCggIUOvWrfX2229fVrMAAABXA5e/nnvppZf07LPPasSIEeYP9n722WcaNmyYjh07pjFjxpR7kwAAAO7mcmh69dVXNX/+fD366KPmtnvvvVctWrTQlClTCE0AAOCa5PLXc0eOHFHnzp1Lbe/cubOOHDlSLk0BAAB4GpdDU5MmTbR8+fJS25ctW6amTZuWS1MAAACexuWv56ZOnap+/fpp8+bN5pqmzz//XKmpqWWGKQAAgGuBy0ea4uLitHXrVtWuXVsrV67UypUrVbt2bW3btk33339/RfQIAADgdpd1ccuIiAgtWbKkvHsBAADwWOX223MAAADXMstHmry9vS955W8vLy+dO3fuDzcFAADgaSyHpg8++OB3x9LT0/XKK6+ouLi4XJoCAADwNJZD03333Vdq2759+zRx4kR99NFHGjBggNMP5QIAAFxLLmtN0+HDhzV06FC1atVK586d044dO7R48WI1bNiwvPsDAADwCC6Fpry8PE2YMEFNmjTRnj17lJqaqo8++kgtW7asqP4AAAA8guWv52bOnKl//vOfCg4O1r/+9a8yv64DAAC4VnkZhmFYKfT29lZAQICio6Pl4+Pzu3Xvv/9+uTV3NXE4HLLb7crLy5PNZnN3O78rbOJqd7dwzTgwI9bdLQAA/iBXPr8tH2l69NFHL3nJAQAAgGuV5dCUnJxcgW0AAAB4Nq4IDgAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFrg1NE2fPl0dOnRQ9erVVbduXfXq1Uv79u1zqjlz5owSEhJUq1YtVatWTXFxccrOznaqOXjwoGJjY1WlShXVrVtX48aN07lz55xq0tLS1K5dO/n5+alJkyZKTk4u1c/cuXMVFhYmf39/RUZGatu2beX+nAEAwNXJraFp06ZNSkhI0BdffKH169fr7Nmz6tGjh/Lz882aMWPG6KOPPtKKFSu0adMmHT58WL179zbHi4qKFBsbq8LCQm3ZskWLFy9WcnKykpKSzJrMzEzFxsaqe/fu2rFjh0aPHq0hQ4Zo3bp1Zs2yZcuUmJioyZMn66uvvlKbNm0UExOjnJycK/NiAAAAj+ZlGIbh7iZKHD16VHXr1tWmTZt0++23Ky8vT3Xq1NHSpUvVp08fSdLevXvVvHlzpaenq1OnTlq7dq3+9Kc/6fDhwwoKCpIkLViwQBMmTNDRo0fl6+urCRMmaPXq1dq9e7e5r/79+ys3N1cpKSmSpMjISHXo0EFz5syRJBUXFys0NFQjR47UxIkTL9m7w+GQ3W5XXl6ebDZbeb805SZs4mp3t3DNODAj1t0tAAD+IFc+vz1qTVNeXp4kqWbNmpKkjIwMnT17VtHR0WZNs2bN1KBBA6Wnp0uS0tPT1apVKzMwSVJMTIwcDof27Nlj1pw/R0lNyRyFhYXKyMhwqvH29lZ0dLRZc6GCggI5HA6nGwAAuHZ5TGgqLi7W6NGjdeutt6ply5aSpKysLPn6+iowMNCpNigoSFlZWWbN+YGpZLxk7GI1DodDv/76q44dO6aioqIya0rmuND06dNlt9vNW2ho6OU9cQAAcFXwmNCUkJCg3bt3691333V3K5ZMmjRJeXl55u3QoUPubgkAAFSgSu5uQJJGjBihVatWafPmzapfv765PTg4WIWFhcrNzXU62pSdna3g4GCz5sKz3ErOrju/5sIz7rKzs2Wz2RQQECAfHx/5+PiUWVMyx4X8/Pzk5+d3eU8YAABcddx6pMkwDI0YMUIffPCBNmzYoEaNGjmNR0REqHLlykpNTTW37du3TwcPHlRUVJQkKSoqSrt27XI6y239+vWy2WwKDw83a86fo6SmZA5fX19FREQ41RQXFys1NdWsAQAA1ze3HmlKSEjQ0qVL9f/+3/9T9erVzfVDdrtdAQEBstvtGjx4sBITE1WzZk3ZbDaNHDlSUVFR6tSpkySpR48eCg8P1yOPPKKZM2cqKytLzzzzjBISEswjQcOGDdOcOXM0fvx4PfbYY9qwYYOWL1+u1av/70yyxMRExcfHq3379urYsaNefvll5efna9CgQVf+hQEAAB7HraFp/vz5kqRu3bo5bV+0aJEGDhwoSZo1a5a8vb0VFxengoICxcTEaN68eWatj4+PVq1apeHDhysqKkpVq1ZVfHy8pk2bZtY0atRIq1ev1pgxYzR79mzVr19fb7zxhmJiYsyafv366ejRo0pKSlJWVpbatm2rlJSUUovDAQDA9cmjrtN0NeM6TdcfrtNUfnhflg/ek4DrrtrrNAEAAHgqQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALKjk7gYAAPA0YRNXu7uFa8aBGbHubqHccKQJAADAAkITAACABW4NTZs3b9af//xnhYSEyMvLSytXrnQaNwxDSUlJqlevngICAhQdHa3vv//eqebEiRMaMGCAbDabAgMDNXjwYJ0+fdqpZufOnerSpYv8/f0VGhqqmTNnluplxYoVatasmfz9/dWqVSutWbOm3J8vAAC4erk1NOXn56tNmzaaO3dumeMzZ87UK6+8ogULFmjr1q2qWrWqYmJidObMGbNmwIAB2rNnj9avX69Vq1Zp8+bNevzxx81xh8OhHj16qGHDhsrIyNDzzz+vKVOmaOHChWbNli1b9OCDD2rw4MH6+uuv1atXL/Xq1Uu7d++uuCcPAACuKl6GYRjubkKSvLy89MEHH6hXr16SfjvKFBISoqeeekpjx46VJOXl5SkoKEjJycnq37+/vvvuO4WHh2v79u1q3769JCklJUX33HOP/vvf/yokJETz58/X008/raysLPn6+kqSJk6cqJUrV2rv3r2SpH79+ik/P1+rVq0y++nUqZPatm2rBQsWlNlvQUGBCgoKzPsOh0OhoaHKy8uTzWYr99envLC4sfxcS4sb3Y33ZfngPVl+eE+WH09/XzocDtntdkuf3x67pikzM1NZWVmKjo42t9ntdkVGRio9PV2SlJ6ersDAQDMwSVJ0dLS8vb21detWs+b22283A5MkxcTEaN++fTp58qRZc/5+SmpK9lOW6dOny263m7fQ0NA//qQBAIDH8tjQlJWVJUkKCgpy2h4UFGSOZWVlqW7duk7jlSpVUs2aNZ1qyprj/H38Xk3JeFkmTZqkvLw883bo0CFXnyIAALiKcJ2my+Tn5yc/Pz93twEAAK4Qjz3SFBwcLEnKzs522p6dnW2OBQcHKycnx2n83LlzOnHihFNNWXOcv4/fqykZBwAA8NjQ1KhRIwUHBys1NdXc5nA4tHXrVkVFRUmSoqKilJubq4yMDLNmw4YNKi4uVmRkpFmzefNmnT171qxZv369br75ZtWoUcOsOX8/JTUl+wEAAHBraDp9+rR27NihHTt2SPpt8feOHTt08OBBeXl5afTo0fr73/+uDz/8ULt27dKjjz6qkJAQ8wy75s2b6+6779bQoUO1bds2ff755xoxYoT69++vkJAQSdJDDz0kX19fDR48WHv27NGyZcs0e/ZsJSYmmn2MGjVKKSkpevHFF7V3715NmTJFX375pUaMGHGlXxIAAOCh3Lqm6csvv1T37t3N+yVBJj4+XsnJyRo/frzy8/P1+OOPKzc3V7fddptSUlLk7+9vPuadd97RiBEjdOedd8rb21txcXF65ZVXzHG73a6PP/5YCQkJioiIUO3atZWUlOR0LafOnTtr6dKleuaZZ/TXv/5VTZs21cqVK9WyZcsr8CoAAICrgcdcp+lq58p1HtyJa4+UH0+/9sjVhPdl+eA9WX54T5YfT39fXhPXaQIAAPAkhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGh6QJz585VWFiY/P39FRkZqW3btrm7JQAA4AEITedZtmyZEhMTNXnyZH311Vdq06aNYmJilJOT4+7WAACAmxGazvPSSy9p6NChGjRokMLDw7VgwQJVqVJFb775prtbAwAAblbJ3Q14isLCQmVkZGjSpEnmNm9vb0VHRys9Pb1UfUFBgQoKCsz7eXl5kiSHw1Hxzf4BxQW/uLuFa4an/11fTXhflg/ek+WH92T58fT3ZUl/hmFcspbQ9L+OHTumoqIiBQUFOW0PCgrS3r17S9VPnz5dU6dOLbU9NDS0wnqEZ7G/7O4OAGe8J+GJrpb35alTp2S32y9aQ2i6TJMmTVJiYqJ5v7i4WCdOnFCtWrXk5eXlxs6ufg6HQ6GhoTp06JBsNpu72wF4T8Lj8J4sP4Zh6NSpUwoJCblkLaHpf9WuXVs+Pj7Kzs522p6dna3g4OBS9X5+fvLz83PaFhgYWJEtXndsNhv/M4BH4T0JT8N7snxc6ghTCRaC/y9fX19FREQoNTXV3FZcXKzU1FRFRUW5sTMAAOAJONJ0nsTERMXHx6t9+/bq2LGjXn75ZeXn52vQoEHubg0AALgZoek8/fr109GjR5WUlKSsrCy1bdtWKSkppRaHo2L5+flp8uTJpb7+BNyF9yQ8De9J9/AyrJxjBwAAcJ1jTRMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYwCUHAADwcMeOHdObb76p9PR0ZWVlSZKCg4PVuXNnDRw4UHXq1HFzh9cHLjkAAC7Izs7Wa6+9pqSkJHe3guvE9u3bFRMToypVqig6Otq8dmB2drZSU1P1yy+/aN26dWrfvr2bO732EZrg0Q4dOqTJkyfrzTffdHcrgCTpm2++Ubt27VRUVOTuVnCd6NSpk9q0aaMFCxaU+kF4wzA0bNgw7dy5U+np6W7q8PpBaIJH4wMKV9rOnTsvOr537149+OCDvCdxxQQEBOjrr79Ws2bNyhzfu3evbrnlFv36669XuLPrD2ua4FYffvjhRcd//PHHK9QJ8Ju2bdvKy8tLZf17smT7hf/aBypScHCwtm3b9ruhadu2bfzc1xVCaIJb9erV63c/oErwAYUrqWbNmpo5c6buvPPOMsf37NmjP//5z1e4K1zPxo4dq8cff1wZGRm68847S61pev311/XCCy+4ucvrA6EJblWvXj3NmzdP9913X5njO3bsUERExBXuCteziIgIHT58WA0bNixzPDc396IhHyhvCQkJql27tmbNmqV58+aZXw37+PgoIiJCycnJ6tu3r5u7vD4QmuBWERERysjI+N3QdKmjUEB5GzZsmPLz8393vEGDBlq0aNEV7AiQ+vXrp379+uns2bM6duyYJKl27dqqXLmymzu7vrAQHG716aefKj8/X3fffXeZ4/n5+fryyy/VtWvXK9wZ8H8+//xztW/fXn5+fu5uBYAbEZoA4BJsNpt27NihG2+80d2tAHAjfkYFAC6Bf1sCkAhNAAAAlhCaAOASXnvtNa6DA4A1TQAAAFZwpAkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAoAxpaWny8vJSbm6uu1sB4CEITQA82tGjRzV8+HA1aNBAfn5+Cg4OVkxMjD7//PNy20e3bt00evRop22dO3fWkSNHZLfby20/l2vgwIHq1auXu9sArnv8YC8AjxYXF6fCwkItXrxYN954o7Kzs5Wamqrjx49X6H59fX0VHBxcofsAcJUxAMBDnTx50pBkpKWlXbRm8ODBRu3atY3q1asb3bt3N3bs2GGOT5482WjTpo3x1ltvGQ0bNjRsNpvRr18/w+FwGIZhGPHx8YYkp1tmZqaxceNGQ5Jx8uRJwzAMY9GiRYbdbjc++ugj46abbjICAgKMuLg4Iz8/30hOTjYaNmxoBAYGGiNHjjTOnTtn7v/MmTPGU089ZYSEhBhVqlQxOnbsaGzcuNEcL5k3JSXFaNasmVG1alUjJibGOHz4sNn/hf2d/3gAVw5fzwHwWNWqVVO1atW0cuVKFRQUlFnzwAMPKCcnR2vXrlVGRobatWunO++8UydOnDBrfvjhB61cuVKrVq3SqlWrtGnTJs2YMUOSNHv2bEVFRWno0KE6cuSIjhw5otDQ0DL39csvv+iVV17Ru+++q5SUFKWlpen+++/XmjVrtGbNGr399tt67bXX9N5775mPGTFihNLT0/Xuu+9q586deuCBB3T33Xfr+++/d5r3hRde0Ntvv63Nmzfr4MGDGjt2rCRp7Nix6tu3r+6++26zv86dO//h1xbAZXB3agOAi3nvvfeMGjVqGP7+/kbnzp2NSZMmGd98841hGIbx6aefGjabzThz5ozTYxo3bmy89tprhmH8dqSmSpUq5pElwzCMcePGGZGRkeb9rl27GqNGjXKao6wjTZKM/fv3mzV/+ctfjCpVqhinTp0yt8XExBh/+ctfDMMwjJ9++snw8fExfv75Z6e577zzTmPSpEm/O+/cuXONoKAg8358fLxx3333WXq9AFQc1jQB8GhxcXGKjY3Vp59+qi+++EJr167VzJkz9cYbbyg/P1+nT59WrVq1nB7z66+/6ocffjDvh4WFqXr16ub9evXqKScnx+VeqlSposaNG5v3g4KCFBYWpmrVqjltK5l7165dKioq0k033eQ0T0FBgVPPF857uf0BqFiEJgAez9/fX3fddZfuuusuPfvssxoyZIgmT56sJ554QvXq1VNaWlqpxwQGBpp/rly5stOYl5eXiouLXe6jrHkuNvfp06fl4+OjjIwM+fj4ONWdH7TKmsPgZ0EBj0NoAnDVCQ8P18qVK9WuXTtlZWWpUqVKCgsLu+z5fH19VVRUVH4N/q9bbrlFRUVFysnJUZcuXS57norqD4BrWAgOwGMdP35cd9xxh5YsWaKdO3cqMzNTK1as0MyZM3XfffcpOjpaUVFR6tWrlz7++GMdOHBAW7Zs0dNPP60vv/zS8n7CwsK0detWHThwQMeOHbuso1BluemmmzRgwAA9+uijev/995WZmalt27Zp+vTpWr16tUv97dy5U/v27dOxY8d09uzZcukPgGsITQA8VrVq1RQZGalZs2bp9ttvV8uWLfXss89q6NChmjNnjry8vLRmzRrdfvvtGjRokG666Sb1799fP/30k4KCgizvZ+zYsfLx8VF4eLjq1KmjgwcPlttzWLRokR599FE99dRTuvnmm9WrVy9t375dDRo0sDzH0KFDdfPNN6t9+/aqU6dOuV7YE4B1XgZfnAMAAFwSR5oAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsOD/AxEd2cOwE7mYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id                 user_id  \\\n",
       "0           0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA   \n",
       "1           1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q   \n",
       "2           2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A   \n",
       "3           3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ   \n",
       "4           4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ   \n",
       "\n",
       "              business_id  stars  useful  funny  cool  \\\n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw      3       0      0     0   \n",
       "1  7ATYjTIgM3jUlt4UM3IypQ      5       1      0     1   \n",
       "2  YjUWPpI6HXG530lwP-fb2A      3       0      0     0   \n",
       "3  kxX2SOes4o-D3ZQBkiMRfA      5       1      0     1   \n",
       "4  e4Vwtrqf-wpJfwesgvdgxQ      4       1      0     1   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11   \n",
       "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18   \n",
       "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30   \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03   \n",
       "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15   \n",
       "\n",
       "   sentiment  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(top_data_df['stars'].value_counts())\n",
    "\n",
    "# Function to map stars to sentiment\n",
    "def map_sentiment(stars_received):\n",
    "    if stars_received <= 2:\n",
    "        return -1\n",
    "    elif stars_received == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "# Mapping stars to sentiment into three categories\n",
    "top_data_df['sentiment'] = [ map_sentiment(x) for x in top_data_df['stars']]\n",
    "# Plotting the sentiment distribution\n",
    "plt.figure()\n",
    "pd.value_counts(top_data_df['sentiment']).plot.bar(title=\"Sentiment distribution in df\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in df\")\n",
    "plt.show()\n",
    "top_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After segregating and taking equal number of rows for each sentiment:\n",
      " 1    10000\n",
      "-1    10000\n",
      " 0    10000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6AxgBCNX_PNTOxmbRSwcKQ</td>\n",
       "      <td>r3zeYsv1XFBRA4dJpL78cw</td>\n",
       "      <td>gmjsEdUsKpj9Xxu6pdjH0g</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Loved this tour! I grabbed a groupon and the p...</td>\n",
       "      <td>2015-01-03 23:21:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>_ZeMknuYdlQcUqng_Im3yg</td>\n",
       "      <td>yfFzsLmaWF2d4Sr0UNbBgg</td>\n",
       "      <td>LHSTtnW3YHCeUkRDGyJOyw</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazingly amazing wings and homemade bleu chee...</td>\n",
       "      <td>2015-08-07 02:29:16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>rGQRf8UafX7OTlMNN19I8A</td>\n",
       "      <td>1WHRWwQmZOZDAhp2Qyny4g</td>\n",
       "      <td>uMvVYRgGNXf5boolA9HXTw</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My experience with Shalimar was nothing but wo...</td>\n",
       "      <td>2015-06-21 14:48:06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>l3Wk_mvAog6XANIuGQ9C7Q</td>\n",
       "      <td>ZbqSHbgCjzVAqaa7NKWn5A</td>\n",
       "      <td>EQ-TZ2eeD_E0BHuvoaeG5Q</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Locals recommended Milktooth, and it's an amaz...</td>\n",
       "      <td>2015-08-19 14:31:45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>XW_LfMv0fV21l9c6xQd_lw</td>\n",
       "      <td>9OAtfnWag-ajVxRbUTGIyg</td>\n",
       "      <td>lj-E32x9_FA7GmUrBGBEWg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Love going here for happy hour or dinner!  Gre...</td>\n",
       "      <td>2014-06-27 22:44:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>8JFGBuHMoiNDyfcxuWNtrA</td>\n",
       "      <td>smOvOajNG0lS4Pq7d8g4JQ</td>\n",
       "      <td>RZtGWDLCAtuipwaZ-UfjmQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good food--loved the gnocchi with marinara\\nth...</td>\n",
       "      <td>2009-10-14 19:57:14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>UBp0zWyH60Hmw6Fsasei7w</td>\n",
       "      <td>4Uh27DgGzsp6PqrH913giQ</td>\n",
       "      <td>otQS34_MymijPTdNBoBdCw</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>The bun makes the Sonoran Dog. It's like a snu...</td>\n",
       "      <td>2011-10-27 17:12:05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0               review_id                 user_id  \\\n",
       "1            1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q   \n",
       "3            3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ   \n",
       "4            4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ   \n",
       "6            6  6AxgBCNX_PNTOxmbRSwcKQ  r3zeYsv1XFBRA4dJpL78cw   \n",
       "7            7  _ZeMknuYdlQcUqng_Im3yg  yfFzsLmaWF2d4Sr0UNbBgg   \n",
       "10          10  rGQRf8UafX7OTlMNN19I8A  1WHRWwQmZOZDAhp2Qyny4g   \n",
       "11          11  l3Wk_mvAog6XANIuGQ9C7Q  ZbqSHbgCjzVAqaa7NKWn5A   \n",
       "12          12  XW_LfMv0fV21l9c6xQd_lw  9OAtfnWag-ajVxRbUTGIyg   \n",
       "13          13  8JFGBuHMoiNDyfcxuWNtrA  smOvOajNG0lS4Pq7d8g4JQ   \n",
       "14          14  UBp0zWyH60Hmw6Fsasei7w  4Uh27DgGzsp6PqrH913giQ   \n",
       "\n",
       "               business_id  stars  useful  funny  cool  \\\n",
       "1   7ATYjTIgM3jUlt4UM3IypQ      5       1      0     1   \n",
       "3   kxX2SOes4o-D3ZQBkiMRfA      5       1      0     1   \n",
       "4   e4Vwtrqf-wpJfwesgvdgxQ      4       1      0     1   \n",
       "6   gmjsEdUsKpj9Xxu6pdjH0g      5       0      2     0   \n",
       "7   LHSTtnW3YHCeUkRDGyJOyw      5       2      0     0   \n",
       "10  uMvVYRgGNXf5boolA9HXTw      5       2      0     0   \n",
       "11  EQ-TZ2eeD_E0BHuvoaeG5Q      4       0      0     0   \n",
       "12  lj-E32x9_FA7GmUrBGBEWg      4       0      0     0   \n",
       "13  RZtGWDLCAtuipwaZ-UfjmQ      4       0      0     0   \n",
       "14  otQS34_MymijPTdNBoBdCw      4       0      2     0   \n",
       "\n",
       "                                                 text                 date  \\\n",
       "1   I've taken a lot of spin classes over the year...  2012-01-03 15:28:18   \n",
       "3   Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03   \n",
       "4   Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15   \n",
       "6   Loved this tour! I grabbed a groupon and the p...  2015-01-03 23:21:18   \n",
       "7   Amazingly amazing wings and homemade bleu chee...  2015-08-07 02:29:16   \n",
       "10  My experience with Shalimar was nothing but wo...  2015-06-21 14:48:06   \n",
       "11  Locals recommended Milktooth, and it's an amaz...  2015-08-19 14:31:45   \n",
       "12  Love going here for happy hour or dinner!  Gre...  2014-06-27 22:44:01   \n",
       "13  Good food--loved the gnocchi with marinara\\nth...  2009-10-14 19:57:14   \n",
       "14  The bun makes the Sonoran Dog. It's like a snu...  2011-10-27 17:12:05   \n",
       "\n",
       "    sentiment  \n",
       "1           1  \n",
       "3           1  \n",
       "4           1  \n",
       "6           1  \n",
       "7           1  \n",
       "10          1  \n",
       "11          1  \n",
       "12          1  \n",
       "13          1  \n",
       "14          1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to retrieve top few number of each category\n",
    "def get_top_data(top_n = 5000):\n",
    "    top_data_df_positive = top_data_df[top_data_df['sentiment'] == 1].head(top_n)\n",
    "    top_data_df_negative = top_data_df[top_data_df['sentiment'] == -1].head(top_n)\n",
    "    top_data_df_neutral = top_data_df[top_data_df['sentiment'] == 0].head(top_n)\n",
    "    top_data_df_small = pd.concat([top_data_df_positive, top_data_df_negative, top_data_df_neutral])\n",
    "    return top_data_df_small\n",
    "\n",
    "# Function call to get the top 10000 from each sentiment\n",
    "top_data_df_small = get_top_data(top_n=10000)\n",
    "\n",
    "# After selecting top few samples of each sentiment\n",
    "print(\"After segregating and taking equal number of rows for each sentiment:\")\n",
    "print(top_data_df_small['sentiment'].value_counts())\n",
    "top_data_df_small.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant good service!!\n",
      "I like food!!\n",
      "This product good!!\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "print(remove_stopwords(\"Restaurant had a really good service!!\"))\n",
    "print(remove_stopwords(\"I did not like the food!!\"))\n",
    "print(remove_stopwords(\"This product is not good!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     [ve, taken, lot, of, spin, classes, over, the,...\n",
      "3     [wow, yummy, different, delicious, our, favori...\n",
      "4     [cute, interior, and, owner, gave, us, tour, o...\n",
      "6     [loved, this, tour, grabbed, groupon, and, the...\n",
      "7     [amazingly, amazing, wings, and, homemade, ble...\n",
      "10    [my, experience, with, shalimar, was, nothing,...\n",
      "11    [locals, recommended, milktooth, and, it, an, ...\n",
      "12    [love, going, here, for, happy, hour, or, dinn...\n",
      "13    [good, food, loved, the, gnocchi, with, marina...\n",
      "14    [the, bun, makes, the, sonoran, dog, it, like,...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "top_data_df_small['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in top_data_df_small['text']] \n",
    "print(top_data_df_small['tokenized_text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     [ve, taken, lot, of, spin, class, over, the, y...\n",
       "3     [wow, yummi, differ, delici, our, favorit, is,...\n",
       "4     [cute, interior, and, owner, gave, us, tour, o...\n",
       "6     [love, thi, tour, grab, groupon, and, the, pri...\n",
       "7     [amazingli, amaz, wing, and, homemad, bleu, ch...\n",
       "10    [my, experi, with, shalimar, wa, noth, but, wo...\n",
       "11    [local, recommend, milktooth, and, it, an, ama...\n",
       "12    [love, go, here, for, happi, hour, or, dinner,...\n",
       "13    [good, food, love, the, gnocchi, with, marinar...\n",
       "14    [the, bun, make, the, sonoran, dog, it, like, ...\n",
       "Name: stemmed_tokens, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "# Get the stemmed_tokens\n",
    "top_data_df_small['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in top_data_df_small['tokenized_text'] ]\n",
    "top_data_df_small['stemmed_tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      " 1    7036\n",
      "-1    7008\n",
      " 0    6956\n",
      "Name: sentiment, dtype: int64\n",
      "Value counts for Test sentiments\n",
      " 0    3044\n",
      "-1    2992\n",
      " 1    2964\n",
      "Name: sentiment, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "   index             business_id  cool                 date  funny  \\\n",
      "0  41964  h7zxeLAdUyAO6S6UzXJDwA     0  2018-05-20 02:15:46      0   \n",
      "1  21237  ySXKjndttZjNy3kcqRqG3g     0  2015-12-20 20:30:12      0   \n",
      "2  43742  9gObo5ltOMo6UgsaXaHPWA     0  2015-12-05 23:57:22      0   \n",
      "3  35107  tvbFcYCEQWc76CUK-nBw8w     0  2018-07-27 08:09:21      0   \n",
      "4   2960  Yv6HUVu7fRMnt_NtGdVQBw     0  2018-06-19 18:16:51      0   \n",
      "\n",
      "                review_id  stars  \\\n",
      "0  xkcYjM_5w9rdSiN8_Qz_Tg      1   \n",
      "1  XIYnB19-LAI_yzJfB2d7eQ      3   \n",
      "2  Nm2XaG0sQ7p3LHoZG44cAg      1   \n",
      "3  L8Ape_IoEHiMjgiufwCp8Q      3   \n",
      "4  0uD1hdeUNPyfAaGOKpMMeQ      5   \n",
      "\n",
      "                                                text  useful  \\\n",
      "0  Kids talking and being disruptive during the w...       1   \n",
      "1  I've had the clam chowder here about 5 times. ...       1   \n",
      "2  Horrible service. We made a reservation on Yel...       0   \n",
      "3  Decent Korean barbeque, but subpar cold buckwh...       0   \n",
      "4  This is one of our favorite spots in Nashville...       0   \n",
      "\n",
      "                  user_id                                     stemmed_tokens  \n",
      "0  sZwPzjw85nriL8tf2k_yLw  [kid, talk, and, be, disrupt, dure, the, whole...  \n",
      "1  Xp3-2ZMn5mxD--SH7mBKag  [ve, had, the, clam, chowder, here, about, tim...  \n",
      "2  q_9dwLqRBM4FkxtMjHe3qQ  [horribl, servic, we, made, reserv, on, yelp, ...  \n",
      "3  c9QdM3JbLT5sCwQ4hGcHIQ  [decent, korean, barbequ, but, subpar, cold, b...  \n",
      "4  DWGywipRRede0hIpZ4tDag  [thi, is, on, of, our, favorit, spot, in, nash...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Train Test Split Function\n",
    "def split_train_test(top_data_df_small, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(top_data_df_small[['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text', 'useful', 'user_id', 'stemmed_tokens']], \n",
    "                                                        top_data_df_small['sentiment'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(top_data_df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "size = 500\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "# Function to train word2vec model\n",
    "def make_word2vec_model(top_data_df_small, padding=True, sg=1, min_count=1, size=500, workers=3, window=3):\n",
    "    if  padding:\n",
    "        print(len(top_data_df_small))\n",
    "        temp_df = pd.Series(top_data_df_small['stemmed_tokens']).values\n",
    "        temp_df = list(temp_df)\n",
    "        temp_df.append(['pad'])\n",
    "        word2vec_file = os.path.join(OUTPUT_FOLDER,'models/', 'word2vec_' + str(size) + '_PAD.model')\n",
    "    else:\n",
    "        temp_df = top_data_df_small['stemmed_tokens']\n",
    "        word2vec_file = os.path.join(OUTPUT_FOLDER, 'models/' ,'word2vec_' + str(size) + '.model')\n",
    "    w2v_model = Word2Vec(temp_df, min_count = min_count, vector_size = size, workers = workers, window = window, sg = sg)\n",
    "\n",
    "    w2v_model.save(word2vec_file)\n",
    "    return w2v_model, word2vec_file\n",
    "\n",
    "# Train Word2vec model\n",
    "word2vec_file = os.path.join(OUTPUT_FOLDER, 'models', 'word2vec_' + str(size) + '_PAD.model')\n",
    "if not os.path.exists(word2vec_file):\n",
    "    if not os.path.exists(os.path.dirname(word2vec_file)):\n",
    "        os.makedirs(os.path.dirname(word2vec_file))\n",
    "    w2vmodel, word2vec_file = make_word2vec_model(top_data_df_small, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)\n",
    "else:\n",
    "    w2vmodel = Word2Vec.load(word2vec_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.key_to_index['pad']\n",
    "w2vmodel.wv.index_to_key[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sen_len = top_data_df_small.stemmed_tokens.map(len).max()\n",
    "padding_idx = w2vmodel.wv.key_to_index['pad']\n",
    "def make_word2vec_vector_cnn(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2vmodel.wv.key_to_index:\n",
    "            padded_X[i] = 0\n",
    "            print(word)\n",
    "        else:\n",
    "            padded_X[i] = w2vmodel.wv.key_to_index[word]\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get the output tensor\n",
    "def make_target(label):\n",
    "    if label == -1:\n",
    "        return torch.tensor([0], dtype=torch.long, device=device)\n",
    "    elif label == 0:\n",
    "        return torch.tensor([1], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        return torch.tensor([2], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 500\n",
    "NUM_FILTERS = 10\n",
    "import gensim\n",
    "\n",
    "class CnnTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes, window_sizes=(1,2,3,5)):\n",
    "        super(CnnTextClassifier, self).__init__()\n",
    "        w2vmodel = gensim.models.KeyedVectors.load(os.path.join(OUTPUT_FOLDER, 'models/', 'word2vec_500_PAD.model'))\n",
    "        weights = w2vmodel.wv\n",
    "        # With pretrained embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=w2vmodel.wv.key_to_index['pad'])\n",
    "        # Without pretrained embeddings\n",
    "        # self.embedding = nn.Embedding(vocab_size, EMBEDDING_SIZE)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "                                   nn.Conv2d(1, NUM_FILTERS, [window_size, EMBEDDING_SIZE], padding=(window_size - 1, 0))\n",
    "                                   for window_size in window_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(NUM_FILTERS * len(window_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) # [B, T, E]\n",
    "\n",
    "        # Apply a convolution + max_pool layer for each window size\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        xs = []\n",
    "        for conv in self.convs:\n",
    "            x2 = torch.tanh(conv(x))\n",
    "            x2 = torch.squeeze(x2, -1)\n",
    "            x2 = F.max_pool1d(x2, x2.size(2))\n",
    "            xs.append(x2)\n",
    "        x = torch.cat(xs, 2)\n",
    "\n",
    "        # FC\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        probs = F.softmax(logits, dim = 1)\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "NUM_CLASSES = 3\n",
    "VOCAB_SIZE = len(w2vmodel.wv.index_to_key)\n",
    "\n",
    "cnn_model = CnnTextClassifier(vocab_size=VOCAB_SIZE, num_classes=NUM_CLASSES)\n",
    "cnn_model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "# Open the file for writing loss\n",
    "if not os.path.exists(os.path.join(OUTPUT_FOLDER, 'plots')):\n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, 'plots'))\n",
    "if not os.path.exists(os.path.join(OUTPUT_FOLDER, 'ckpts')):\n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, 'ckpts'))\n",
    "\n",
    "loss_file_name = os.path.join(OUTPUT_FOLDER, 'plots/','cnn_class_big_loss_with_padding.csv') \n",
    "if not os.path.exists(loss_file_name):\n",
    "    with open(loss_file_name,'w') as f:\n",
    "        f.write('iter, loss')\n",
    "        f.write('\\n')\n",
    "    losses = []\n",
    "    cnn_model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch\" + str(epoch + 1))\n",
    "        train_loss = 0\n",
    "        for index, row in tqdm(X_train.iterrows(), total=len(X_train)):\n",
    "            print(index, row)\n",
    "            # Clearing the accumulated gradients\n",
    "            cnn_model.zero_grad()\n",
    "\n",
    "            # Make the bag of words vector for stemmed tokens \n",
    "            bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens'])\n",
    "        \n",
    "            # Forward pass to get output\n",
    "            probs = cnn_model(bow_vec)\n",
    "\n",
    "            # Get the target label\n",
    "            target = make_target(Y_train['sentiment'][index])\n",
    "\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = loss_function(probs, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        # if index == 0:\n",
    "        #     continue\n",
    "        print(\"Score: \" + str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
    "        with open(loss_file_name, 'a') as f:\n",
    "            f.write(str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': cnn_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "                }, os.path.join(OUTPUT_FOLDER, 'ckpts', f'epoch_{epoch}.pt'))\n",
    "        train_loss = 0\n",
    "\n",
    "    torch.save(cnn_model, os.path.join(OUTPUT_FOLDER, 'cnn_big_model_500_with_padding.pth'))\n",
    "    print(\"Input vector\")\n",
    "    print(bow_vec.cpu().numpy())\n",
    "    print(\"Probs\")\n",
    "    print(probs)\n",
    "    print(torch.argmax(probs, dim=1).cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['iter', ' loss'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 9000/9000 [00:12<00:00, 704.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      2992\n",
      "           1       0.62      0.63      0.63      3044\n",
      "           2       0.77      0.78      0.78      2964\n",
      "\n",
      "    accuracy                           0.72      9000\n",
      "   macro avg       0.72      0.72      0.72      9000\n",
      "weighted avg       0.72      0.72      0.72      9000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "bow_cnn_predictions = []\n",
    "original_lables_cnn_bow = []\n",
    "cnn_model =torch.load(os.path.join(OUTPUT_FOLDER, 'cnn_big_model_500_with_padding.pth'))\n",
    "cnn_model.eval()\n",
    "loss_df = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'plots', 'cnn_class_big_loss_with_padding.csv'))\n",
    "print(loss_df.columns)\n",
    "# loss_df.plot('loss')\n",
    "with torch.no_grad():\n",
    "    for index, row in tqdm(X_test.iterrows(), total=len(X_test)):\n",
    "        bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens'])\n",
    "        probs = cnn_model(bow_vec)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        bow_cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        original_lables_cnn_bow.append(make_target(Y_test['sentiment'][index]).cpu().numpy()[0])\n",
    "print(classification_report(original_lables_cnn_bow,bow_cnn_predictions))\n",
    "# loss_file_name = os.path.join(OUTPUT_FOLDER ,  'plots/' , 'cnn_class_big_loss_with_padding.csv')\n",
    "# loss_df = pd.read_csv(loss_file_name)\n",
    "# print(loss_df.columns)\n",
    "# plt_500_padding_30_epochs = loss_df[' loss'].plot()\n",
    "# fig = plt_500_padding_30_epochs.get_figure()\n",
    "# fig.savefig(os.path.join(OUTPUT_FOLDER ,'plots/' , \"loss_plt_500_padding_30_epochs.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        w2vmodel = gensim.models.KeyedVectors.load(os.path.join(OUTPUT_FOLDER, 'models/', 'word2vec_500_PAD.model'))\n",
    "        weights = w2vmodel.wv\n",
    "        # With pretrained embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=w2vmodel.wv.key_to_index['pad'])\n",
    "        # embedding and LSTM layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size, train_on_gpu=True):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21000/21000 [22:40<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1,0.0\n",
      "Epoch2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21000/21000 [22:41<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2,0.0\n",
      "Epoch3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21000/21000 [22:08<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 3,0.0\n",
      "Epoch4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21000/21000 [21:51<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 4,0.0\n",
      "Epoch5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21000/21000 [21:51<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 5,0.0\n",
      "Input vector\n",
      "[[  34  288 2478    1  175   22    7  201    1  248   86  188   12   78\n",
      "   997  272 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113 1113\n",
      "  1113 1113 1113]]\n",
      "Probs\n",
      "tensor([0.5042], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProbs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[39mprint\u001b[39m(probs)\n\u001b[0;32m---> 78\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49margmax(probs, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "NUM_CLASSES = 3\n",
    "VOCAB_SIZE = len(w2vmodel.wv.index_to_key)\n",
    "\n",
    "lstm_model = SentimentLSTM(vocab_size=VOCAB_SIZE, output_size=NUM_CLASSES, embedding_dim=EMBEDDING_SIZE, hidden_dim = 256, n_layers=2)\n",
    "lstm_model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "\n",
    "# Open the file for writing loss\n",
    "if not os.path.exists(os.path.join(OUTPUT_FOLDER, 'lstm', 'plots')):\n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, 'lstm', 'plots'))\n",
    "if not os.path.exists(os.path.join(OUTPUT_FOLDER, 'lstm', 'ckpts')):\n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, 'lstm', 'ckpts'))\n",
    "\n",
    "loss_file_name = os.path.join(OUTPUT_FOLDER, 'lstm', 'plots/','lstm_class_big_loss_with_padding.csv') \n",
    "with open(loss_file_name,'w') as f:\n",
    "    f.write('iter, loss')\n",
    "    f.write('\\n')\n",
    "losses = []\n",
    "lstm_model.train()\n",
    "batch_size = 1 #len(X_train)\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch\" + str(epoch + 1))\n",
    "    train_loss = 0\n",
    "    h = lstm_model.init_hidden(batch_size)\n",
    "    for index, row in tqdm(X_train.iterrows(), total=len(X_train)):\n",
    "        # Clearing the accumulated gradients\n",
    "        lstm_model.zero_grad()\n",
    "\n",
    "        # Make the bag of words vector for stemmed tokens \n",
    "        bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens'])\n",
    "        \n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "       \n",
    "        # Forward pass to get output\n",
    "        probs, h = lstm_model(bow_vec, h)\n",
    "\n",
    "        # Get the target label\n",
    "        target = make_target(Y_train['sentiment'][index])\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = loss_function(probs, target.float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        nn.utils.clip_grad_norm_(lstm_model.parameters(), 5)\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # if index == 0:\n",
    "    #     continue\n",
    "    print(\"Score: \" + str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
    "    with open(loss_file_name, 'a') as f:\n",
    "        f.write(str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
    "        f.write('\\n')\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': cnn_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            }, os.path.join(OUTPUT_FOLDER, 'lstm', 'ckpts', f'epoch_{epoch}.pt'))\n",
    "    train_loss = 0\n",
    "\n",
    "torch.save(lstm_model, os.path.join(OUTPUT_FOLDER, 'lstm', 'lstm_big_model_500_with_padding.pth'))\n",
    "print(\"Input vector\")\n",
    "print(bow_vec.cpu().numpy())\n",
    "print(\"Probs\")\n",
    "print(probs)\n",
    "print(torch.argmax(probs, dim=1).cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "bow_lstm_predictions = []\n",
    "original_lables_lstm_bow = []\n",
    "lstm_model = torch.load(os.path.join(OUTPUT_FOLDER, 'lstm', 'lstm_big_model_500_with_padding.pth'))\n",
    "lstm_model.eval()\n",
    "loss_df = pd.read_csv(os.path.join(OUTPUT_FOLDER, 'lstm', 'plots', 'lstm_class_big_loss_with_padding.csv'))\n",
    "print(loss_df.columns)\n",
    "# loss_df.plot('loss')\n",
    "batch_size=1\n",
    "h = lstm_model.init_hidden(batch_size)\n",
    "with torch.no_grad():\n",
    "    for index, row in tqdm(X_test.iterrows(), total=len(X_test)):\n",
    "        bow_vec = make_word2vec_vector_cnn(row['stemmed_tokens'])\n",
    "        h = tuple([each.data for each in h])\n",
    "        probs, h = lstm_model(bow_vec, h)\n",
    "        # _, predicted = torch.max(probs.data, 1)\n",
    "        bow_lstm_predictions.append(probs.cpu().numpy()[0])\n",
    "        original_lables_lstm_bow.append(make_target(Y_test['sentiment'][index]).cpu().numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2992\n",
      "           1       0.34      1.00      0.51      3044\n",
      "           2       0.00      0.00      0.00      2964\n",
      "\n",
      "    accuracy                           0.34      9000\n",
      "   macro avg       0.11      0.33      0.17      9000\n",
      "weighted avg       0.11      0.34      0.17      9000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parker-alien/miniconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/parker-alien/miniconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/parker-alien/miniconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(original_lables_lstm_bow,list(map(round,bow_lstm_predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "# Define a custom dataset class that inherits from PyTorch's Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.data_x = X\n",
    "        self.data_y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        def make_target_lstm(label):\n",
    "            if label == -1:\n",
    "                return 0\n",
    "            elif label == 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        max_sen_len = top_data_df_small.stemmed_tokens.map(len).max()\n",
    "        padding_idx = w2vmodel.wv.key_to_index['pad']\n",
    "        def make_word2vec_vector_lstm(sentence):\n",
    "            padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "            i = 0\n",
    "            for word in sentence:\n",
    "                if word not in w2vmodel.wv.key_to_index:\n",
    "                    padded_X[i] = 0\n",
    "                    print(word)\n",
    "                else:\n",
    "                    padded_X[i] = w2vmodel.wv.key_to_index[word]\n",
    "                i += 1\n",
    "            return np.array(padded_X)\n",
    "        x = self.data_x.iloc[index, self.data_x.columns.get_loc('stemmed_tokens')]\n",
    "        y = self.data_y.iloc[index, self.data_y.columns.get_loc(\"sentiment\")]\n",
    "        return make_word2vec_vector_lstm(x), make_target_lstm(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "class EmbeddingLSTM(nn.Module):\n",
    "    \"\"\" LSTM Model that learns its own character embeddings. Max index 256 hardcoded. \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initalize new EmbeddingLSTM model.\n",
    "        :keyword hidden_size: number of hidden units.\n",
    "        :keyword num_layers: number of LSTM layers.\n",
    "        :keyword embedding_dim: Dimensionality of the embeddings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = kwargs[\"hidden_size\"]\n",
    "        self.num_layers = kwargs[\"num_layers\"]\n",
    "        self.output_size = kwargs[\"output_size\"]\n",
    "        self.embedding_dim = kwargs[\"embedding_dim\"]\n",
    "        self.input_size = kwargs['input_size']\n",
    "        w2vmodel = gensim.models.KeyedVectors.load(os.path.join(OUTPUT_FOLDER, 'models/', 'word2vec_500_PAD.model'))\n",
    "        weights = w2vmodel.wv\n",
    "        # With pretrained embeddings\n",
    "        # self.char_embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=w2vmodel.wv.key_to_index['pad']).cuda()\n",
    "        self.char_embeddings = nn.Embedding(self.input_size,  embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        self.output_layer = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        lengths= len(sequence)\n",
    "        embeds = self.char_embeddings(sequence.cuda())\n",
    "\n",
    "        \n",
    "        self.h0 = Variable(torch.cuda.FloatTensor(self.num_layers, lengths, self.hidden_size).fill_(0.))\n",
    "        self.c0 = Variable(torch.cuda.FloatTensor(self.num_layers, lengths, self.hidden_size).fill_(0.))\n",
    "        output, hn = self.lstm(embeds.permute(1, 0, 2), (self.h0, self.c0))\n",
    "        lstm_out = output.contiguous().view(-1, self.hidden_size)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = out.view(lengths, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return torch.round(sig_out)\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"EmbeddingLSTM_h{}_l{}_i{}_e{}\".format(self.hidden_size, self.num_layers, self.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n",
      "-150.637804746627822559\n",
      "Score: 1,tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [02:30<1:12:56, 150.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch2\n",
      "-152.264958858493291016\n",
      "Score: 2,tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [05:03<1:10:52, 151.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch3\n",
      "-151.374551534652790625\n",
      "Score: 3,tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [07:35<1:08:17, 151.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch4\n",
      "-150.336386680603031152\n",
      "Score: 4,tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [10:05<1:05:33, 151.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch5\n",
      "-149.951744318008423775\n",
      "Score: 5,tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [12:35<1:02:52, 150.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch6\n",
      "-149.812263011932375586\n",
      "Score: 6,tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [15:05<1:00:14, 150.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch7\n",
      "-149.765389919281332527\n",
      "Score: 7,tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [17:35<57:39, 150.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch8\n",
      "-150.238314151763927969\n",
      "Score: 8,tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [20:06<55:09, 150.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch9\n",
      "-149.805785655975346699\n",
      "Score: 9,tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [22:36<52:36, 150.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch10\n",
      "-149.633454799652143367\n",
      "Score: 10,tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [25:06<50:03, 150.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch11\n",
      "-150.130679845809940684\n",
      "Score: 11,tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [27:36<47:34, 150.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch12\n",
      "-149.499754905700689043\n",
      "Score: 12,tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [30:06<45:01, 150.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch13\n",
      "-149.223922729492246875\n",
      "Score: 13,tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [32:36<42:28, 149.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch14\n",
      "-149.320744991302529395\n",
      "Score: 14,tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [35:05<39:56, 149.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch15\n",
      "-149.549003124237067402\n",
      "Score: 15,tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [37:35<37:27, 149.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch16\n",
      "-149.755682229995737138\n",
      "Score: 16,tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [40:05<34:58, 149.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch17\n",
      "-150.046119213104251626\n",
      "Score: 17,tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [42:35<32:29, 150.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch18\n",
      "-149.528529405593872031\n",
      "Score: 18,tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [45:05<29:59, 149.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch19\n",
      "-149.636194705963134355\n",
      "Score: 19,tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [47:35<27:29, 149.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch20\n",
      "-149.609053134918226562\n",
      "Score: 20,tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [50:05<24:59, 149.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch21\n",
      "-149.804746627807625156\n",
      "Score: 21,tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [52:35<22:29, 149.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch22\n",
      "-150.500510931015018223\n",
      "Score: 22,tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [55:06<20:01, 150.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch23\n",
      "-150.522924900054931934\n",
      "Score: 23,tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [57:36<17:32, 150.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch24\n",
      "-149.207970380783085024\n",
      "Score: 24,tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [1:00:06<15:00, 150.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch25\n",
      "-149.530556440353487509\n",
      "Score: 25,tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [1:02:36<12:29, 150.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch26\n",
      "-152.143159866333377441\n",
      "Score: 26,tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [1:05:08<10:02, 150.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch27\n",
      "-149.801032781600958965\n",
      "Score: 27,tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [1:07:38<07:31, 150.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch28\n",
      "-151.848104000091554531\n",
      "Score: 28,tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [1:10:10<05:02, 151.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch29\n",
      "-152.564974546432507915\n",
      "Score: 29,tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [1:12:43<02:31, 151.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch30\n",
      "-151.918122768402138383\n",
      "Score: 30,tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [1:15:15<00:00, 150.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "NUM_CLASSES = 3\n",
    "VOCAB_SIZE = len(w2vmodel.wv.index_to_key)\n",
    "\n",
    "lstm_model = EmbeddingLSTM(input_size=VOCAB_SIZE, output_size=NUM_CLASSES, hidden_size = 256, num_layers=2, embedding_dim=EMBEDDING_SIZE)\n",
    "lstm_model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "dataset = MyDataset(X_train, Y_train)\n",
    "\n",
    "# Define the batch size you want to use for training\n",
    "batch_size = 32\n",
    "\n",
    "# Use DataLoader to create batches\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Open the file for writing loss\n",
    "model_name = 'lstm3'\n",
    "if not os.path.exists(os.path.join(OUTPUT_FOLDER, model_name, 'plots')):\n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, model_name, 'plots'))\n",
    "if not os.path.exists(os.path.join(OUTPUT_FOLDER, model_name, 'ckpts')):\n",
    "    os.makedirs(os.path.join(OUTPUT_FOLDER, model_name, 'ckpts'))\n",
    "\n",
    "loss_file_name = os.path.join(OUTPUT_FOLDER, model_name, 'plots/',f'{model_name}_class_big_loss_with_padding.csv') \n",
    "if os.path.exists(loss_file_name):\n",
    "    with open(loss_file_name,'w') as f:\n",
    "        f.write('iter, loss')\n",
    "        f.write('\\n')\n",
    "    lstm_model.train()\n",
    "    lstm_model.cuda()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print(\"Epoch\" + str(epoch + 1))\n",
    "        \n",
    "        prev_time = time.time()\n",
    "        start_time = time.time()\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            \n",
    "            cur_time = time.time()\n",
    "            print(i, cur_time-prev_time, end ='\\r')\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch.to(torch.device('cuda'))\n",
    "            y_batch.to(torch.device('cuda'))\n",
    "            # Clearing the accumulated gradients\n",
    "            lstm_model.zero_grad()\n",
    "\n",
    "            # Make the bag of words vector for stemmed tokens \n",
    "        \n",
    "            # Forward pass to get output\n",
    "            probs = lstm_model(x_batch)\n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = loss_function(probs, y_batch.float().cuda())\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "            prev_time =cur_time\n",
    "        print(start_time - time.time())\n",
    "\n",
    "        # if index == 0:\n",
    "        #     continue\n",
    "        print(\"Score: \" + str((epoch+1)) + \",\" + str(loss / len(X_train)))\n",
    "        with open(loss_file_name, 'a') as f:\n",
    "            f.write(str((epoch+1)) + \",\" + str(loss / len(X_train)))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': cnn_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss.item(),\n",
    "                }, os.path.join(OUTPUT_FOLDER, model_name, 'ckpts', f'epoch_{epoch}.pt'))\n",
    "\n",
    "    torch.save(lstm_model, os.path.join(OUTPUT_FOLDER, model_name, f'{model_name}_big_model_500_with_padding.pth'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['iter', ' loss'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "bow_lstm_predictions = []\n",
    "original_lables_lstm_bow = []\n",
    "lstm_model.eval()\n",
    "model_name = 'lstm2'\n",
    "loss_df = pd.read_csv(os.path.join(OUTPUT_FOLDER, model_name, 'plots', f'{model_name}_class_big_loss_with_padding.csv'))\n",
    "print(loss_df.columns)\n",
    "# loss_df.plot('loss')\n",
    "dataloader = DataLoader(MyDataset(X_test, Y_test))\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        x, y = data\n",
    "        probs = lstm_model(x)\n",
    "        # _, predicted = torch.max(probs.data, 1)\n",
    "        bow_lstm_predictions.append(probs.cpu().numpy()[0])\n",
    "        original_lables_lstm_bow.append(y.cpu().numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50      2992\n",
      "           1       0.00      0.00      0.00      3044\n",
      "           2       0.00      0.00      0.00      2964\n",
      "\n",
      "    accuracy                           0.33      9000\n",
      "   macro avg       0.11      0.33      0.17      9000\n",
      "weighted avg       0.11      0.33      0.17      9000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parker-alien/miniconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/parker-alien/miniconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/parker-alien/miniconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(original_lables_lstm_bow,list(map(round, bow_lstm_predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['iter', ' loss'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "bow_lstm_predictions = []\n",
    "original_lables_lstm_bow = []\n",
    "lstm_model.eval()\n",
    "model_name = 'lstm3'\n",
    "loss_df = pd.read_csv(os.path.join(OUTPUT_FOLDER, model_name, 'plots', f'{model_name}_class_big_loss_with_padding.csv'))\n",
    "print(loss_df.columns)\n",
    "# loss_df.plot('loss')\n",
    "dataloader = DataLoader(MyDataset(X_test, Y_test))\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        x, y = data\n",
    "        probs = lstm_model(x)\n",
    "        # _, predicted = torch.max(probs.data, 1)\n",
    "        bow_lstm_predictions.append(probs.cpu().numpy()[0])\n",
    "        original_lables_lstm_bow.append(y.cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(original_lables_lstm_bow,list(map(round, bow_lstm_predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13445163\n",
      "14694838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['char_embeddings.weight', torch.Size([26780, 500]), 13390000],\n",
       " ['lstm.weight_ih_l0', torch.Size([1024, 500]), 512000],\n",
       " ['lstm.weight_hh_l0', torch.Size([1024, 256]), 262144],\n",
       " ['lstm.bias_ih_l0', torch.Size([1024]), 1024],\n",
       " ['lstm.bias_hh_l0', torch.Size([1024]), 1024],\n",
       " ['lstm.weight_ih_l1', torch.Size([1024, 256]), 262144],\n",
       " ['lstm.weight_hh_l1', torch.Size([1024, 256]), 262144],\n",
       " ['lstm.bias_ih_l1', torch.Size([1024]), 1024],\n",
       " ['lstm.bias_hh_l1', torch.Size([1024]), 1024],\n",
       " ['output_layer.weight', torch.Size([3, 256]), 768],\n",
       " ['output_layer.bias', torch.Size([3]), 3],\n",
       " ['fc.weight', torch.Size([3, 512]), 1536],\n",
       " ['fc.bias', torch.Size([3]), 3]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "VOCAB_SIZE = len(w2vmodel.wv.index_to_key)\n",
    "NUM_CLASSES = 3\n",
    "max_sen_len = top_data_df_small.stemmed_tokens.map(len).max()\n",
    "cnn_model = CnnTextClassifier(vocab_size=VOCAB_SIZE, num_classes=NUM_CLASSES)\n",
    "lstm_model = EmbeddingLSTM(output_size=NUM_CLASSES, hidden_size = 256, num_layers=2, embedding_dim=EMBEDDING_SIZE)\n",
    "cnn_model =torch.load(os.path.join(OUTPUT_FOLDER, 'cnn_big_model_500_with_padding.pth'))\n",
    "# summary(cnn_model, (1, max_sen_len))\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "print(get_n_params(cnn_model))\n",
    "print(get_n_params(lstm_model))\n",
    "[[p[0], p[1].size(), len(p[1].flatten())] for p in list(lstm_model.named_parameters())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['embedding.weight', torch.Size([26780, 500]), 13390000],\n",
       " ['convs.0.weight', torch.Size([10, 1, 1, 500]), 5000],\n",
       " ['convs.0.bias', torch.Size([10]), 10],\n",
       " ['convs.1.weight', torch.Size([10, 1, 2, 500]), 10000],\n",
       " ['convs.1.bias', torch.Size([10]), 10],\n",
       " ['convs.2.weight', torch.Size([10, 1, 3, 500]), 15000],\n",
       " ['convs.2.bias', torch.Size([10]), 10],\n",
       " ['convs.3.weight', torch.Size([10, 1, 5, 500]), 25000],\n",
       " ['convs.3.bias', torch.Size([10]), 10],\n",
       " ['fc.weight', torch.Size([3, 40]), 120],\n",
       " ['fc.bias', torch.Size([3]), 3]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[p[0], p[1].size(), len(p[1].flatten())] for p in list(cnn_model.named_parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = EmbeddingLSTM(input_size=VOCAB_SIZE, output_size=NUM_CLASSES, hidden_size = 256, num_layers=2, embedding_dim=EMBEDDING_SIZE)\n",
    "[[p[0], p[1].size(), len(p[1].flatten())] for p in list(lstm_model.named_parameters())]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnnhw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
